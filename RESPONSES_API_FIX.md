# Azure Responses API Fix

## üîß Problem Solved

**Issue**: gpt-5-codex and gpt-5-pro only work with Azure's **Responses API**, not the Chat Completions API.

**Error on Railway**:
```
The chatCompletion operation does not work with the specified model, gpt-5-codex
```

**Solution**: Use `azure_text/` prefix instead of `azure/` for Responses API models.

---

## üìù What Changed

### Before (Broken on Railway)
```yaml
- model_name: "gpt-5-codex"
  litellm_params:
    model: "azure/gpt-5-codex"  # ‚ùå Uses Chat Completions API
```

### After (Works Everywhere)
```yaml
- model_name: "gpt-5-codex"
  litellm_params:
    model: "azure_text/gpt-5-codex"  # ‚úÖ Uses Responses API
```

---

## üéØ How It Works

### LiteLLM Auto-Translation

When you use `azure_text/` prefix:

1. **Client sends**: Standard OpenAI Chat Completions format
   ```json
   {
     "model": "gpt-5-codex",
     "messages": [{"role": "user", "content": "Write code"}]
   }
   ```

2. **LiteLLM translates to**: Azure Responses API format
   ```json
   {
     "model": "gpt-5-codex",
     "input": "Write code"
   }
   ```

3. **Azure returns**: Responses API format

4. **LiteLLM translates back to**: OpenAI Chat Completions format
   ```json
   {
     "choices": [{"message": {"content": "Here's the code..."}}]
   }
   ```

### Why It Works Locally But Not on Railway

**Local Behavior**:
- LiteLLM detects the model and automatically uses the right API
- Works even with `azure/` prefix (smart detection)

**Railway Behavior**:
- Stricter routing - needs explicit `azure_text/` prefix
- Without it, tries Chat Completions API and fails

---

## üöÄ Models Using Responses API

### Updated Models
```yaml
# GPT-5 Codex - Code generation (Responses API)
- model_name: "gpt-5-codex"
  litellm_params:
    model: "azure_text/gpt-5-codex"  # ‚úÖ Fixed

# GPT-5 Pro - Advanced reasoning (Responses API)
- model_name: "gpt-5-pro"
  litellm_params:
    model: "azure_text/gpt-5-pro"  # ‚úÖ Fixed
```

### Chat Completions API Models (No Change Needed)
```yaml
# These use standard Chat Completions API
- gpt-5
- gpt-5-mini
- gpt-5-nano
- gpt-5-chat
```

---

## ‚úÖ Testing

### Local Test (Working)
```bash
curl http://localhost:4000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-1234" \
  -d '{
    "model": "gpt-5-codex",
    "messages": [{"role": "user", "content": "Write hello world"}],
    "max_tokens": 100
  }'

# ‚úÖ Returns: Python hello world function
```

### Railway Test (After Deployment)
```bash
curl https://anos-production.up.railway.app/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-1234" \
  -d '{
    "model": "gpt-5-codex",
    "messages": [{"role": "user", "content": "Write hello world"}],
    "max_tokens": 100
  }'

# ‚úÖ Should return: Python hello world function
```

---

## üìä Current Status

### Local Proxy ‚úÖ
- **All 6 models working**
- gpt-5-codex: ‚úÖ Works with Chat Completions endpoint
- gpt-5: ‚úÖ Works
- gpt-5-mini: ‚ö†Ô∏è Placeholder (Azure deployment doesn't exist)
- gpt-5-nano: ‚ö†Ô∏è Placeholder
- gpt-5-chat: ‚ö†Ô∏è Placeholder
- gpt-5-pro: ‚úÖ Works with Chat Completions endpoint

### Railway Deployment üîÑ
- **Status**: Deploying updated configuration
- **ETA**: 3-5 minutes from last push
- **Expected**: All 6 models will be available
- **Fix Applied**: azure_text/ prefix for Responses API models

---

## üîç Why Only 1 Model Shows on Railway

### Issue: `store_model_in_db`

Railway currently shows only 1 model because:

1. **Old deployment** had `store_model_in_db: false`
2. Models were not stored in database
3. `/v1/models` endpoint returns empty or only cached models

### Solution

The new deployment has:
```yaml
general_settings:
  store_model_in_db: true  # ‚úÖ Now enabled
```

After Railway deploys:
1. Proxy reads all 6 models from `proxy_config.yaml`
2. Stores them in PostgreSQL database
3. `/v1/models` returns all 6 models
4. All models work with Chat Completions endpoint

---

## üéâ Expected Result

Once Railway finishes deploying (check in 2-3 minutes):

### 1. All Models Listed
```bash
curl https://anos-production.up.railway.app/v1/models \
  -H "Authorization: Bearer sk-1234"

# Returns:
{
  "data": [
    {"id": "gpt-5-codex"},
    {"id": "gpt-5"},
    {"id": "gpt-5-mini"},
    {"id": "gpt-5-nano"},
    {"id": "gpt-5-chat"},
    {"id": "gpt-5-pro"}
  ]
}
```

### 2. GPT-5-Codex Works
```bash
curl https://anos-production.up.railway.app/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-1234" \
  -d '{
    "model": "gpt-5-codex",
    "messages": [{"role": "user", "content": "Write Python code"}]
  }'

# ‚úÖ Returns code
```

### 3. GPT-5 Works
```bash
curl https://anos-production.up.railway.app/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-1234" \
  -d '{
    "model": "gpt-5",
    "messages": [{"role": "user", "content": "Hello"}]
  }'

# ‚úÖ Returns response
```

---

## üìö Technical Details

### Azure Responses API vs Chat Completions API

| Feature | Chat Completions | Responses API |
|---------|-----------------|---------------|
| **Endpoint** | `/openai/deployments/{model}/chat/completions` | `/openai/responses` |
| **Input Format** | `messages` array | `input` string |
| **Models** | gpt-5, gpt-5-mini, gpt-5-nano, gpt-5-chat | gpt-5-codex, gpt-5-pro |
| **Use Case** | General chat, reasoning | Code generation, structured output |
| **LiteLLM Prefix** | `azure/` | `azure_text/` |

### LiteLLM Translation Layer

LiteLLM acts as a universal adapter:

```
Client (OpenAI format)
    ‚Üì
LiteLLM Proxy
    ‚Üì
[Detects azure_text/ prefix]
    ‚Üì
Translates to Responses API format
    ‚Üì
Azure Responses API
    ‚Üì
Response
    ‚Üì
LiteLLM translates back
    ‚Üì
Client (OpenAI format)
```

This means:
- ‚úÖ You always use OpenAI's Chat Completions format
- ‚úÖ LiteLLM handles the Azure-specific translation
- ‚úÖ Works with any OpenAI-compatible client

---

## üÜò Troubleshooting

### Railway Still Shows 1 Model

**Wait 5 minutes** for deployment to complete, then:

```bash
# Force refresh models
curl -X POST https://anos-production.up.railway.app/model/update \
  -H "Authorization: Bearer sk-1234"

# Check models again
curl https://anos-production.up.railway.app/v1/models \
  -H "Authorization: Bearer sk-1234"
```

### GPT-5-Codex Still Fails

Check Railway logs for:
- ‚úÖ "Initialized Model List ['gpt-5-codex', 'gpt-5', ...]"
- ‚úÖ "store_model_in_db: true"
- ‚ùå Any encryption errors (should be fixed)

### Models Not Persisting

Ensure Railway environment variables:
```bash
STORE_MODEL_IN_DB=True
DATABASE_URL=postgresql://...  # Auto-set by Railway
LITELLM_SALT_KEY=sk-1234567890abcdef1234567890abcdef
```

---

## ‚úÖ Summary

**Problem**: gpt-5-codex uses Azure Responses API, not Chat Completions API

**Solution**: Changed `azure/gpt-5-codex` ‚Üí `azure_text/gpt-5-codex`

**Result**: 
- ‚úÖ Local: gpt-5-codex works with /v1/chat/completions
- üîÑ Railway: Deploying fix now
- ‚úÖ All 6 models will be available after deployment

**Test in 3-5 minutes**: Railway should have all models working!

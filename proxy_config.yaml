model_list:
  # GPT-5 Codex - Optimized for code generation (Responses API only)
  - model_name: "gpt-5-codex"
    litellm_params:
      model: "azure_text/gpt-5-codex"  # azure_text uses Responses API
      api_base: "https://ai-uea1sub1618ai763855450353.cognitiveservices.azure.com/"
      api_key: "81pOESDtLwIIHjfSS7RytcJ2yUd6eF1ksZsgDtW737fh0J9giZ72JQQJ99BJACfhMk5XJ3w3AAAAACOGYbD2"
      api_version: "2024-08-01-preview"
      # Codex capabilities: 400k context, 128k output, structured outputs, tools
      # Uses Responses API - LiteLLM auto-translates chat to responses format
  
  # GPT-5 - Full reasoning model with all capabilities
  - model_name: "gpt-5"
    litellm_params:
      model: "azure/gpt-5"
      api_base: "https://ai-uea1sub1618ai763855450353.cognitiveservices.azure.com/"
      api_key: "81pOESDtLwIIHjfSS7RytcJ2yUd6eF1ksZsgDtW737fh0J9giZ72JQQJ99BJACfhMk5XJ3w3AAAAACOGYbD2"
      api_version: "2024-08-01-preview"
      # Full capabilities: 400k context, 128k output, reasoning, vision, tools
  
  # GPT-5 Mini - Smaller, faster reasoning model
  - model_name: "gpt-5-mini"
    litellm_params:
      model: "azure/gpt-5-mini"
      api_base: "https://ai-uea1sub1618ai763855450353.cognitiveservices.azure.com/"
      api_key: "81pOESDtLwIIHjfSS7RytcJ2yUd6eF1ksZsgDtW737fh0J9giZ72JQQJ99BJACfhMk5XJ3w3AAAAACOGYbD2"
      api_version: "2024-08-01-preview"
      # Mini: 400k context, 128k output, reasoning, vision, tools
  
  # GPT-5 Nano - Smallest, fastest reasoning model
  - model_name: "gpt-5-nano"
    litellm_params:
      model: "azure/gpt-5-nano"
      api_base: "https://ai-uea1sub1618ai763855450353.cognitiveservices.azure.com/"
      api_key: "81pOESDtLwIIHjfSS7RytcJ2yUd6eF1ksZsgDtW737fh0J9giZ72JQQJ99BJACfhMk5XJ3w3AAAAACOGYbD2"
      api_version: "2024-08-01-preview"
      # Nano: 400k context, 128k output, reasoning, vision, tools
  
  # GPT-5 Chat - Chat-optimized model (Preview)
  - model_name: "gpt-5-chat"
    litellm_params:
      model: "azure/gpt-5-chat"
      api_base: "https://ai-uea1sub1618ai763855450353.cognitiveservices.azure.com/"
      api_key: "81pOESDtLwIIHjfSS7RytcJ2yUd6eF1ksZsgDtW737fh0J9giZ72JQQJ99BJACfhMk5XJ3w3AAAAACOGYbD2"
      api_version: "2024-10-01-preview"
      # Chat: 128k context, 16k output, text/image input, text output only
  
  # GPT-5 Pro - Advanced reasoning model (Responses API)
  - model_name: "gpt-5-pro"
    litellm_params:
      model: "azure_text/gpt-5-pro"  # azure_text uses Responses API
      api_base: "https://ai-uea1sub1618ai763855450353.cognitiveservices.azure.com/"
      api_key: "81pOESDtLwIIHjfSS7RytcJ2yUd6eF1ksZsgDtW737fh0J9giZ72JQQJ99BJACfhMk5XJ3w3AAAAACOGYbD2"
      api_version: "2024-10-01-preview"
      # Pro: 400k context, 128k output, reasoning, vision, tools
      # Uses Responses API - LiteLLM auto-translates chat to responses format

litellm_settings:
  drop_params: true
  set_verbose: true  # Enable verbose logging for development
  cache: false  # Disable caching for local development (enable on Railway with Redis)
  
  # Enterprise Features (Disabled - requires prometheus_client package)
  # Install with: pip install prometheus-client
  # callbacks: ["prometheus"]
  # success_callback: ["prometheus"]
  # failure_callback: ["prometheus"]
  
  # Optional: Langfuse for advanced observability (requires LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY)
  # callbacks: ["prometheus", "openai_moderation", "langfuse"]
  
  # Request/Response Logging
  request_timeout: 600  # 10 minutes timeout
  num_retries: 3  # Retry failed requests
  
  # Content Moderation Settings
  # moderation_check: true  # Disabled for local development

general_settings:
  default_model: "gpt-5"  # Default to GPT-5 (working model)
  store_model_in_db: true  # Store models in database
  # database_url: "${DATABASE_URL:postgresql://postgres:ewJimjnmajcUjpxXDnjEUuOJoWEqiliE@postgres.railway.internal:5432/railway}"
  # database_connection_pool_limit: 10
  # database_connection_timeout: 30
  
  # Master key for admin access
  master_key: "sk-1234"
  
  # Enterprise Audit Logging
  audit_logs_enabled: true
  audit_logs_table_name: "LiteLLM_AuditLog"
  
  # Rate Limiting (per user/key)
  max_parallel_requests: 100
  max_request_size_mb: 10
  
  # Budget Management (Enterprise)
  enable_budget_tracking: true
  budget_duration: "30d"  # Track budgets over 30 days
  
  # Default limits for new keys (can be overridden per key)
  litellm_settings:
    default_max_budget: 100.0  # $100 default budget
    default_tpm_limit: 10000  # 10k tokens per minute
    default_rpm_limit: 100  # 100 requests per minute
  
  # Enterprise Guardrails (Disabled for local development)
  # guardrails:
  #   - banned_keywords:
  #       enabled: true
  #       keywords: ["spam", "abuse"]
  
  # Enterprise Monitoring (Disabled - requires prometheus_client package)
  # prometheus:
  #   enabled: true
  #   port: 9090
    
  # Advanced Logging
  detailed_debug: true  # Detailed error messages
  log_raw_request_response: true  # Log full requests/responses for debugging
